#?#box#calculatedX@108#calculatedY@98#children@1728912850,1728912869,1728920987#name@seed#id@seed#parent@#x@86#y@78#tag@dwh
content
#?#box#calculatedX@108#calculatedY@98#children@1728913303#name@datalake#id@1728912869#parent@#x@86#y@78
A data lake is a ~*central location~* that holds a large amount of data in its ~*native, raw format~* with metadata tags and a unique identifier
Data lakes consolidate all data in a single location "~*as is~*" without a upfront ~*schema~*
Data in all stages of the refinement process can be stored. Raw data can be ingested and stored alongside structured, tabular data source

zones - There is no standard pattern out there there are multiple terminologies but the common theme is bring data as is , cleanse , build models
some terminologies of zones are 
bronze, silver, gold 
raw, cleanse, enrich, serve 
raw, prepare , curate

~*Raw/Landing~*
    Raw - As is 
    Landing - raw data thats from a recognized source system
    Note: Both in raw and landing data must be in ~*original format~*
~*Raw/Conformance~*
    Data gets converted into the ~*delta lake/other format~* and lands in an input folder. 
    When data quality runs, pass records are copied to output folder. Records that fail land in an error folder.
~*Standardized/Enriched - Ready for analytics~*
    This data layer is considered the ~*silver layer~* or ~*read data source~*. 
    Data within this layer has had ~*no transformations~* applied other than ~*impurity filteration~*, and ~*data type alignment~*.
~*Curated~*
    Data has structure and ready for ~*optimized analytics~*
    thought 1 : This layer is not a replacement for a data warehouse,not good for responsive dashboards.Its best suited for data scientists/advanced data analysis on time insensitive/large scale data as storage costs are lower in your data lake than your data warehouse.
    Datawarehouse/aggregations can be built on spark and published back to datalake
    thought 2: it is good enough for ~*Dimensional modelling~*
=Disadvantages
Reliability
Slow performance as data increases
Security

#?#box#calculatedX@108#calculatedY@98#children@1728920181,1728920199#name@lakeHouse#id@1728913303#parent@#x@86#y@78
https://www.starburst.io/blog/iceberg-vs-delta-lake/
lakeHouse is a datalake with ~*rules on top of it~* 
~*Deltalake~* and ~*iceberg~* are examples of lakeHouse file format

oltp - data lake - propreitary data warehouse
                   vendor lock in
                   cost
                   sometimes DWH is published back to data lake hence duplication
                   data from data lake is copied to DWH so now there are two data sources totally disconnected
                   
LakeHouse architecture
oltp - Data lake + table format ( lake house ) - execution engine
example of architecture flow 
LakeHouse engine ( ~*Spark , Dremio~* )
catalog ( ~*Project Nessie, Hive, AWS Glue~* )
table format ( ~* iceberg ~* ) 
storage layer (~* s3 ~*)
file format (~* parquet ~*)

#?#box#calculatedX@108#calculatedY@98#children@#name@deltaLake#id@1728920181#parent@#x@86#y@78
Deltalake is an open source ~*table storage format~* originally developed by Databricks in 2017(open sourced in 2019) as their ~*data lakehouse table format~*.
Deltalake overcomes lakehouse limitations, it is an open format data management and governance layer that combines the best of both data lakes and data warehouses
DeltaLake seems closely associated with ~*spark~* and ~*databricks~*

Features of DeltaLake
Ability to update and delete records quickly 
ACID compliance 
Schema Evolution
Time Travel 

#?#box#calculatedX@108#calculatedY@98#children@1731671202,1731926427#name@Iceberg#id@1728920199#parent@#x@86#y@78
Apache Iceberg was created by Netflix as a replacement for ~*Hive data lakes~* in 2017. Iceberg ran on ~*Trino~* clusters. 
designed for ~*larger datasets~* that changed ~*too frequently~* for Hive. 
Iceberg has same object storage Hive used, but collects ~*additional metadata~*. 
Icebergs ~*metadata management~* is the key to its architecture, and allows for data warehouse-like functionality using cloud object storage. 
Iceberg is now Apache foundation open source table format in many data lakehouse solutions. 
!! NOTE - These are historical issues , some might have been fixed as part of new updates !!
Hive uses ~*folder structured~* file format with folders for tables and sub folders for partition. Users need to know this ~*physical layout~* for writing efficient queries
Folder structure format does not work well with ~*cloud object storage~*
Very difficult to update ~*few records in large files~*, hive updates ~*whole partition~* instead of part files. Even if it can updating part file will for few records will still be inefficient
Every update needed a ~*analyse stats~* again
Multiple parallel writes causes consistent read problems, Hive now supports ~*consistent snapshot~* 
hive now supports some features of acid such as update, delete for ~*ORC~* files, but still no support for READ COMMITTED, DIRTY READ etc

#?#box#calculatedX@108#calculatedY@98#children@#name@intro#id@1731671202#parent@#x@86#y@78
iceberg is a ~*file format specification~*, it is not a ~*storage or exection engine~*
The specification is implemented by multiple tools with their own ~*readers and writers~* such as ~*Spark and Flink~*
iceberg comes with an api not sure how it works with every tool and object storage
table is a ~*canonical list of files~* - like pointer to any location 
iceberg does not make ~*edits~* to files but creates incremental change files and hence can update one file / one record without rewriting the whole partition
write create ~*snapshot~* hence it supports ~*time travel~*.~*multiple write~* is supported, and collects ~*file metadata~*,~*column stats~* during write
~*write compaction~* regularly merges small files 
hidden partition - timestamp ia aware of month year date ????????
tables can evolve ~*schema~* and also ~*partition~* 

#?#box#calculatedX@108#calculatedY@98#children@1731927525,1731927705,1731927750#name@structure#id@1731926427#parent@#x@86#y@78
https://www.dremio.com/resources/guides/apache-iceberg-an-architectural-look-under-the-covers/#h-manifest-file
iceberg meta files are file format agnostic

catalog 
metadata files
manifest list
manifest files 
data files 

C:\Users\mithu\Desktop\projects\d3\map\resources\
    iceberg_manifest.png
    iceberg_manifest_list.png
    iceberg_metadata.png
#?#box#calculatedX@108#calculatedY@98#children@#name@metadata#id@1731927525#parent@#x@86#y@78
{
    "format-version" : 1,
    "table-uuid" : "4b96b6e8-9838-48df-a111-ec1ff6422816",
    "location" : "/home/hadoop/warehouse/db2/part_table2",
    "last-updated-ms" : 1611694436618,
    "last-column-id" : 3,
    "schema" : {
        "type" : "struct",
        "fields" : [ {
            "id" : 1,
            "name" : "id",
            "required" : true,
            "type" : "int"
        }, {
            "id" : 2,
            "name" : "ts",
            "required" : false,
            "type" : "timestamptz"
        }, {
            "id" : 3,
            "name" : "message",
            "required" : false,
            "type" : "string"
        } ]
    },
    "partition-spec" : [ {
        "name" : "ts_hour",
        "transform" : "hour",
        "source-id" : 2,
        "field-id" : 1000
    } ],
    "default-spec-id" : 0,
    "partition-specs" : [ {
        "spec-id" : 0,
        "fields" : [ {
            "name" : "ts_hour",
            "transform" : "hour",
            "source-id" : 2,
            "field-id" : 1000
        } ]
    } ],
    "default-sort-order-id" : 0,
    "sort-orders" : [ {
        "order-id" : 0,
        "fields" : [ ]
    } ],
    "properties" : {
        "owner" : "hadoop"
    },
    "current-snapshot-id" : 1257424822184505371,
    "snapshots" : [ {
        "snapshot-id" : 8271497753230544300,
        "timestamp-ms" : 1611694406483,
        "summary" : {
            "operation" : "append",
            "spark.app.id" : "application_1611687743277_0002",
            "added-data-files" : "1",
            "added-records" : "1",
            "added-files-size" : "960",
            "changed-partition-count" : "1",
            "total-records" : "1",
            "total-data-files" : "1",
            "total-delete-files" : "0",
            "total-position-deletes" : "0",
            "total-equality-deletes" : "0"
        },
        "manifest-list" : "/home/hadoop/warehouse/db2/part_table2/metadata/snap-8271497753230544300-1-d8a778f9-ad19-4e9c-88ff-28f49ec939fa.avro"
    }, 
    {
        "snapshot-id" : 1257424822184505371,
        "parent-snapshot-id" : 8271497753230544300,
        "timestamp-ms" : 1611694436618,
        "summary" : {
            "operation" : "append",
            "spark.app.id" : "application_1611687743277_0002",
            "added-data-files" : "1",
            "added-records" : "1",
            "added-files-size" : "973",
            "changed-partition-count" : "1",
            "total-records" : "2",
            "total-data-files" : "2",
            "total-delete-files" : "0",
            "total-position-deletes" : "0",
            "total-equality-deletes" : "0"
        },
        "manifest-list" : "/home/hadoop/warehouse/db2/part_table2/metadata/snap-1257424822184505371-1-eab8490b-8d16-4eb1-ba9e-0dede788ff08.avro"
    } ],
    "snapshot-log" : [ {
        "timestamp-ms" : 1611694406483,
        "snapshot-id" : 8271497753230544300
    }, 
    {
        "timestamp-ms" : 1611694436618,
        "snapshot-id" : 1257424822184505371
    } ],
    "metadata-log" : [ {
        "timestamp-ms" : 1611694097253,
        "metadata-file" : "/home/hadoop/warehouse/db2/part_table2/metadata/v1.metadata.json"
    }, 
    {
        "timestamp-ms" : 1611694406483,
        "metadata-file" : "/home/hadoop/warehouse/db2/part_table2/metadata/v2.metadata.json"
    } ]
}

#?#box#calculatedX@108#calculatedY@98#children@#name@manifestList#id@1731927705#parent@#x@86#y@78
snap-1257424822184505371-1-eab8490b-8d16-4eb1-ba9e-0dede788ff08.avro (converted to JSON)

{
    "manifest_path": "/home/hadoop/warehouse/db2/part_table2/metadata/eab8490b-8d16-4eb1-ba9e-0dede788ff08-m0.avro",
    "manifest_length": 4884,
    "partition_spec_id": 0,
    "added_snapshot_id": {
        "long": 1257424822184505300
    },
    "added_data_files_count": {
        "int": 1
    },
    "existing_data_files_count": {
        "int": 0
    },
    "deleted_data_files_count": {
        "int": 0
    },
    "partitions": {
        "array": [ {
            "contains_null": false,
            "lower_bound": {
                "bytes": "¹Ô\\u0006\\u0000"
            },
            "upper_bound": {
                "bytes": "¹Ô\\u0006\\u0000"
            }
        } ]
    },
    "added_rows_count": {
        "long": 1
    },
    "existing_rows_count": {
        "long": 0
    },
    "deleted_rows_count": {
        "long": 0
    }
}
{
    "manifest_path": "/home/hadoop/warehouse/db2/part_table2/metadata/d8a778f9-ad19-4e9c-88ff-28f49ec939fa-m0.avro",
    "manifest_length": 4884,
    "partition_spec_id": 0,
    "added_snapshot_id": {
        "long": 8271497753230544000
    },
    "added_data_files_count": {
        "int": 1
    },
    "existing_data_files_count": {
        "int": 0
    },
    "deleted_data_files_count": {
        "int": 0
    },
    "partitions": {
        "array": [ {
            "contains_null": false,
            "lower_bound": {
                "bytes": "¸Ô\\u0006\\u0000"
            },
            "upper_bound": {
                "bytes": "¸Ô\\u0006\\u0000"
            }
        } ]
    },
    "added_rows_count": {
        "long": 1
    },
    "existing_rows_count": {
        "long": 0
    },
    "deleted_rows_count": {
        "long": 0
    }
}



#?#box#calculatedX@108#calculatedY@98#children@#name@manifest#id@1731927750#parent@#x@86#y@78\
eab8490b-8d16-4eb1-ba9e-0dede788ff08-m0.avro (converted to JSON)

{
    "status": 1,
    "snapshot_id": {
        "long": 1257424822184505300
    },
    "data_file": {
        "file_path": "/home/hadoop/warehouse/db2/part_table2/data/ts_hour=2021-01-26-01/00000-6-7c6cf3c0-8090-4f15-a4cc-3a3a562eed7b-00001.parquet",
        "file_format": "PARQUET",
        "partition": {
            "ts_hour": {
                "int": 447673
            }
        },
        "record_count": 1,
        "file_size_in_bytes": 973,
        "block_size_in_bytes": 67108864,
        "column_sizes": {
            "array": [ {
                "key": 1,
                "value": 47
            },
            {
                "key": 2,
                "value": 57
            },
            {
                "key": 3,
                "value": 60
            } ]
        },
        "value_counts": {
            "array": [ {
                "key": 1,
                "value": 1
            },
            {
                "key": 2,
                "value": 1
            },
            {
                "key": 3,
                "value": 1
            } ]
        },
        "null_value_counts": {
            "array": [ {
                "key": 1,
                "value": 0
            },
            {
                "key": 2,
                "value": 0
            },
            {
                "key": 3,
                "value": 0
            } ]
        },
        "lower_bounds": {
            "array": [ {
                "key": 1,
                "value": "\\u0002\\u0000\\u0000\\u0000"
            },
            {
                "key": 2,
                "value": "\\u0000„ ,Ã¹\\u0005\\u0000"
            },
            {
                "key": 3,
                "value": "test message 2"
            } ]
        },
        "upper_bounds": {
            "array": [ {
                "key": 1,
                "value": "\\u0002\\u0000\\u0000\\u0000"
            },
            {
                "key": 2,
                "value": "\\u0000„ ,Ã¹\\u0005\\u0000"
            },
            {
                "key": 3,
                "value": "test message 2"
            } ]
        },
        "key_metadata": null,
        "split_offsets": {
            "array": [
                4
            ]
        }
    }
}

#?#box#calculatedX@108#calculatedY@98#children@1728920981#name@fileFormat#id@1728920987#parent@#x@86#y@78
#?#box#calculatedX@108#calculatedY@98#children@#name@parquet#id@1728920981#parent@#x@86#y@78

#?#box#calculatedX@108#calculatedY@98#children@1720961745,1720961599#name@datawarehouse#id@1728912850#parent@#x@86#y@78#tag@dwh
content
#?#box#calculatedX@108#calculatedY@98#children@1728824252,1720961704,1720961816,1720961623,1720961660,1720961854#name@architecture#id@1720961599#parent@#x@86#y@78
content
#?#box#calculatedX@108#calculatedY@98#children@#name@coreKimball#id@1728824252#parent@#x@86#y@78
        ETL System:         Presentation Area:      BI Applications:
        = Transform from    = Dimensional (star     = Ad hoc queries
        source-to-target    schema or OLAP          = Standard reports
        = Conform           cube)                   = Analytic apps
        dimensions          = Atomic and            = Data mining and
        = Normalization     summary data            models
SOURCE  optional            = Organized by
SYSTEM  = No user query     business process
        support             = Uses conformed
        Design Goals:       dimensions
        = Throughput        Design Goals:
        = Integrity and     = Ease-of-use
        consistency         = Query performance
                            ==================
                            Enterprise DW Bus
                            Architecture
#?#box#calculatedX@108#calculatedY@98#children@#name@IndependentDataMart#id@1720961704#parent@#x@86#y@78
Independent datamart architecture
Not a Kimball model 
example each BI department gets a data mart of its own
source -> Stage -> datamart 1 -> BI application 1 
       -> Stage -> datamart 2 -> BI application 2  
problem is if departmentA needs customer data they form their own dimension , same for departmentB
Strongly discouraged by Kimball  but it help rapid development since each team is on its own 
sometimes each team has its own staging layer as seen in diagram
Maintenance nightmare
#?#box#calculatedX@108#calculatedY@98#children@#name@hubSpokeCIF#id@1720961816#parent@#x@86#y@78
hub and spoke CIF is advocated by ~*bill Inmon~*
CIF - ~*corporate information factory~*
source -> EDW(~*must be normalized~*) -> Multiple Data Marts
          user queryable             Dimensional 
          3 NF                       Summarized  
          Atomic                     Departmental

Organizations who have adopted the CIF approach often access the EDW repository for ~*detailed queries~*
presentation area is often ~*departmental and summarized~*
Not suitable for large companies as EDW layer is a perfect world 
#?#box#calculatedX@108#calculatedY@98#children@#name@ods#id@1720961623#parent@#x@86#y@78
ODS - ~* operational data store ~*
Front end
processing at row level
no historic data 
no user query allowed
lives outside datawarehouse
#?#box#calculatedX@108#calculatedY@98#children@#name@Staging#id@1720961660#parent@#x@86#y@78
staging reads from ods and is a ~*cleansing~* layer 
can be in ~*3NF~*,called as ~*EDW~* in Inmon, 3NF is also called ~*ER~* model 
Kimball rejects all this calls it ~*staging ~*. if staging is in ~*3NF~* , its called ~*Normalized staging~*. It is offlimits to query 
#?#box#calculatedX@108#calculatedY@98#children@1720961792,1728822873#name@DimensionalModel#id@1720961745#parent@#x@86#y@78
content
#?#box#calculatedX@108#calculatedY@98#children@#name@dimension#id@1720961792#parent@#x@86#y@78
Dimensions must be ~*atomic~* which allows ~*adhoc query~*
Dimensions must be ~*wide~* and ~*descriptive~*
Dimensions must be ~*conformed~* that allows ~*single source of truth~*
#?#box#calculatedX@108#calculatedY@98#children@1729452141,1729452196,1729452611,1732910089,1732910095,1732910123#name@fact#id@1728822873#parent@#x@86#y@78
The term fact represents a ~*business measure~*
The data on each row is at a specific level of detail, referred to as the ~*grain~*, such as one row per product sold on a sales transaction.
facts can be ~*additive, semi-additive, non-additive ~*
Semi-additive facts, such as ~*account balances~*, cannot be summed across the time dimension
Non-additive facts, such as ~*unit prices~*, can never be added
~*Textual facts~* are very rare and must be placed in dimension unless there is a very valid reason ( text is unique for every row in the fact table) 
It is important not to fill ~*no activity items~* because these overwhelm most fact tables.
all fact table grains fall into one of three categories: ~*transaction, periodic snapshot, and accumulating snapshot.~*
Facts are ~*narrow and long~*, have two or more foreign keys that connect to the dimension tables primary keys
The fact table generally has its own primary key composed of a ~*subset of the foreign keys~* called ~*composite key~*.

example
Retail Sales Fact
==================
Date Key (FK)
Product Key (FK)
Store Key (FK)
Promotion Key (FK)
Customer Key (FK)
Clerk Key (FK)
Transaction #
Sales Dollars
Sales Units
#?#box#calculatedX@108#calculatedY@98#children@#name@Transactionfact#id@1729452141#parent@#x@86#y@78
A row in a transaction fact table corresponds to a measurement event at a point in ~*space and time~*
Transaction fact tables may be dense or sparse because rows exist only if ~*measurements take place~*
#?#box#calculatedX@108#calculatedY@98#children@#name@periodicSnapshot#id@1729452196#parent@#x@86#y@78
A row in a periodic snapshot fact table summarizes many measurement events occurring over a ~*standard period~*, such as a ~*day~*, ~*week~*, ~*month~*. 
The grain is the ~*period~*, not the individual transaction.
Often contain many facts because any measurement event consistent with the fact table grain is permissible. 
They have ~*uniformly dense~* foreign keys, even if no activity takes place during the period, a row is typically inserted in the fact table containing a ~*zero or null~* for each fact.

#?#box#calculatedX@108#calculatedY@98#children@#name@accumulatingSnapshot#id@1729452611#parent@#x@86#y@78
Summarizes the measurement events occurring at ~*predictable steps~* between the beginning and the end of a process
There is a ~*date foreign key~* in the fact table for each step in the process of the pipeline
As pipeline progress occurs, the accumulating fact table row is ~*revisited and updated~*.
This consistent updating of accumulating snapshot fact rows is unique among the three types of fact tables

#?#box#calculatedX@108#calculatedY@98#children@#name@factlessfact#id@1732910089#parent@#x@86#y@78
an event of a student attending a class on a given day may not have a recorded numeric fact, but a fact row with foreign keys for calendar day,student, teacher, location, and class is well-defined. This is a factless fact 

it can also be used to analyze what didnt happen. 
These queries always have two parts:
~*factless coverage~* table with all possibilities and an ~*activity table~* that contains the events that did happen. 
When the activity is subtracted from the coverage, the result is the set of events that did not happen.

#?#box#calculatedX@108#calculatedY@98#children@#name@aggregatefact#id@1732910095#parent@#x@86#y@78
Aggregate Fact Tables
Aggregate Fact Tables are simple ~*numeric rollups of atomic fact~* table data built solely to ~*accelerate query performance~*
Aggregate fact tables contain foreign keys to ~*shrunken conformed dimensions~*, as well as ~*aggregated facts~* created by summing measures from more atomic fact tables

~*OLAP cubes~* with summarized measures are built in the same way as relational aggregates, but the OLAP cubes are meant to be accessed directly by the business users.

#?#box#calculatedX@108#calculatedY@98#children@#name@consolidatedFact#id@1732910123#parent@#x@86#y@78
combine facts from multiple processes together into a single consolidated fact table if they can be expressed at the ~*same grain~*. 
For example, ~*sales actuals~* can be consolidated with ~*sales forecasts~* in a single fact table
Consolidated fact tables add burden to  ~*ETL processing~*, but ease the analytic burden on the ~*BI applications~*

#?#box#calculatedX@108#calculatedY@98#children@#name@hybridInmonKimbal#id@1720961854#parent@#x@86#y@78
hybrid CIF KIMBALL
staging is 3NF but off limits to users 
Presentation area has all Kimball qualities eg: atomic dimensions